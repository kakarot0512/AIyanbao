#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import pandas as pd
import logging
import datetime
import json
import google.generativeai as genai
import time
from functools import wraps
from tqdm import tqdm
import yfinance as yf

# --- Configuration ---
# è®¾ç½®æ—¥å¿—è®°å½•ï¼Œä»¥æ˜¾ç¤ºæ—¶é—´æˆ³ã€æ—¥å¿—çº§åˆ«å’Œæ¶ˆæ¯ã€‚
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

# !!! é‡è¦ï¼šè¯·åœ¨æ­¤å¤„è®¾ç½®æ‚¨çš„ Gemini API å¯†é’¥ã€‚!!!
# å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ API å¯†é’¥ï¼Œè„šæœ¬å°†æ— æ³•å·¥ä½œã€‚
GEMINI_API_KEY = "AIzaSyDN5gaSQjFUTSRQGHc3OuGpFpIPsvu3H2U"  # <--- åœ¨è¿™é‡Œæ›¿æ¢æˆä½ çš„çœŸå®å¯†é’¥

# è„šæœ¬è®¾è®¡ä¸ºå§‹ç»ˆä½¿ç”¨ AI åˆ†æã€‚
AI_ANALYSIS_ENABLED = True

if AI_ANALYSIS_ENABLED:
    if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_API_KEY_HERE":
        logging.error("é”™è¯¯: Gemini API å¯†é’¥æœªè®¾ç½®ã€‚è¯·åœ¨è„šæœ¬ä¸­è®¾ç½® GEMINI_API_KEYã€‚")
        AI_ANALYSIS_ENABLED = False
    else:
        try:
            genai.configure(api_key=GEMINI_API_KEY)
        except Exception as e:
            logging.error(f"Gemini API é…ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä½ çš„ API Key: {e}")
            AI_ANALYSIS_ENABLED = False

# --- ç›®å½•è®¾ç½® ---
# å®šä¹‰è¾“å…¥æŠ¥å‘Šã€è¾“å‡ºç»“æœå’ŒåŸå§‹æ•°æ®çš„ç›®å½•ã€‚
DAILY_REPORT_DIR = "æ¯æ—¥æŠ¥å‘Š"
ANALYSIS_RESULT_DIR = "åˆ†æç»“æœ"
RAW_DATA_DIR = "è‚¡ç¥¨åŸå§‹æ•°æ®" # æ–°å¢ï¼šç”¨äºä¿å­˜é›…è™è´¢ç»åŸå§‹æ•°æ®çš„ç›®å½•
os.makedirs(ANALYSIS_RESULT_DIR, exist_ok=True)
os.makedirs(RAW_DATA_DIR, exist_ok=True)


# --- å·¥å…·å‡½æ•° ---
def retry(retries=3, delay=5, backoff=2):
    """
    ä¸€ä¸ªå¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•è£…é¥°å™¨ï¼Œç”¨äºç½‘ç»œè¯·æ±‚ã€‚
    è¿™æœ‰åŠ©äºå¤„ç†ä¸´æ—¶çš„ç½‘ç»œé—®é¢˜æˆ–APIé€Ÿç‡é™åˆ¶ã€‚
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            _retries, _delay = retries, delay
            while _retries > 0:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    _retries -= 1
                    if _retries == 0:
                        logging.warning(f"å‡½æ•° {func.__name__} åœ¨æ‰€æœ‰é‡è¯•åå¤±è´¥: {e}")
                        return None
                    logging.warning(f"å‡½æ•° {func.__name__} å¤±è´¥: {e}. å°†åœ¨ {_delay} ç§’åé‡è¯•... ({_retries} æ¬¡é‡è¯•å‰©ä½™)")
                    time.sleep(_delay)
                    _delay *= backoff
        return wrapper
    return decorator

# --- æŠ¥å‘Šè§£æä¸æ•°æ®è·å–æ¨¡å— ---
def get_latest_report():
    """æŸ¥æ‰¾å¹¶è¿”å›æœ€æ–°çš„æ¯æ—¥æŠ¥å‘Šçš„è·¯å¾„ã€‚"""
    logging.info("æ­£åœ¨æœç´¢æœ€æ–°çš„æ¯æ—¥æŠ¥å‘Š...")
    if not os.path.exists(DAILY_REPORT_DIR):
        logging.error(f"é”™è¯¯: æ¯æ—¥æŠ¥å‘Šç›®å½• '{DAILY_REPORT_DIR}' æœªæ‰¾åˆ°ã€‚")
        return None
    try:
        # æŸ¥æ‰¾æ‰€æœ‰æ—¥æœŸæ ¼å¼çš„å­ç›®å½•
        date_dirs = [d for d in os.listdir(DAILY_REPORT_DIR) if os.path.isdir(os.path.join(DAILY_REPORT_DIR, d)) and re.match(r'^\d{4}-\d{2}-\d{2}$', d)]
        if not date_dirs:
            logging.error(f"åœ¨ '{DAILY_REPORT_DIR}' ä¸­æœªæ‰¾åˆ°æ—¥æœŸæ ¼å¼ (YYYY-MM-DD) çš„å­ç›®å½•ã€‚")
            return None
        date_dirs.sort(key=lambda d: datetime.datetime.strptime(d, '%Y-%m-%d'), reverse=True)
        
        report_date_dir = os.path.join(DAILY_REPORT_DIR, date_dirs[0])
        report_files = [f for f in os.listdir(report_date_dir) if f.endswith('.md')]
        if not report_files:
            logging.error(f"åœ¨ç›®å½• '{report_date_dir}' ä¸­æœªæ‰¾åˆ° .md æ–‡ä»¶ã€‚")
            return None
        report_files.sort(reverse=True)
        
        latest_report = os.path.join(report_date_dir, report_files[0])
        logging.info(f"æˆåŠŸæ‰¾åˆ°æœ€æ–°æŠ¥å‘Š: {latest_report}")
        return latest_report
    except Exception as e:
        logging.error(f"æŸ¥æ‰¾æœ€æ–°æŠ¥å‘Šæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return None

def extract_stock_recommendations(report_path):
    """ä» Markdown æŠ¥å‘Šä¸­è§£æå¹¶æå–æ¨èçš„è‚¡ç¥¨åˆ—è¡¨ã€‚"""
    logging.info(f"æ­£åœ¨ä»æŠ¥å‘Šä¸­æå–è‚¡ç¥¨æ¨è: {report_path}...")
    try:
        with open(report_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ­£åˆ™è¡¨è¾¾å¼å¯»æ‰¾Markdownè¡¨æ ¼
        table_pattern = re.compile(r"\|\s*è‚¡ç¥¨ä»£ç \s*\|\s*å…¬å¸åç§°\s*\|.*?\n(?:\|:?-+:?\|:?-+:?\|.*?\n)((?:\|.*?\|\n)+)", re.DOTALL)
        match = table_pattern.search(content)
        if not match:
            logging.error("åœ¨æŠ¥å‘Šä¸­æ‰¾ä¸åˆ°æ ¼å¼æ­£ç¡®çš„è‚¡ç¥¨æ¨èè¡¨ã€‚")
            return None
        
        table_content = match.group(1).strip()
        rows = [row for row in table_content.split('\n') if row.strip()]
        stocks = []
        for row in rows:
            cells = [c.strip() for c in row.split('|') if c.strip()]
            # ä»…æå–6ä½çº¯æ•°å­—çš„è‚¡ç¥¨ä»£ç 
            if len(cells) >= 2 and re.match(r'^\d{6}$', cells[0]):
                stocks.append({'code': cells[0], 'name': cells[1]})

        if not stocks:
            logging.error("æœªèƒ½ä»è¡¨ä¸­è§£æä»»ä½•æœ‰æ•ˆçš„è‚¡ç¥¨ã€‚")
            return None
            
        logging.info(f"æˆåŠŸæå– {len(stocks)} æ”¯æ¨èè‚¡ç¥¨ã€‚")
        return stocks
    except Exception as e:
        logging.error(f"æå–è‚¡ç¥¨æ¨èæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

def get_yahoo_ticker_symbol(code):
    """ä¸ºé›…è™è´¢ç»è‡ªåŠ¨æ·»åŠ æ­£ç¡®çš„äº¤æ˜“æ‰€åç¼€ã€‚"""
    code_str = str(code).strip()
    if code_str.startswith(('60', '68')): # æ²ªå¸‚ä¸»æ¿ã€ç§‘åˆ›æ¿
        return f"{code_str}.SS"
    elif code_str.startswith(('00', '30', '20')): # æ·±å¸‚ä¸»æ¿ã€åˆ›ä¸šæ¿
        return f"{code_str}.SZ"
    else:
        logging.warning(f"æ— æ³•ç¡®å®šè‚¡ç¥¨ä»£ç  {code_str} çš„äº¤æ˜“æ‰€ã€‚å°†é»˜è®¤å°è¯•ä¸Šäº¤æ‰€ (.SS)ã€‚")
        return f"{code_str}.SS"

@retry(retries=3, delay=10)
def fetch_stock_data_from_yahoo(stock_info):
    """ä»Yahoo Financeè·å–ä¸€æ”¯è‚¡ç¥¨çš„è‚¡ä»·å’Œè´¢åŠ¡æ•°æ®ï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ°ã€‚"""
    code = stock_info['code']
    name = stock_info['name']
    ticker_symbol = get_yahoo_ticker_symbol(code)
    stock_yf = yf.Ticker(ticker_symbol)

    stock_data_package = {"code": code, "name": name}

    # ä¸ºå½“å‰è‚¡ç¥¨åˆ›å»ºç‹¬ç«‹çš„åŸå§‹æ•°æ®å­˜å‚¨ç›®å½•
    stock_raw_data_dir = os.path.join(RAW_DATA_DIR, code)
    os.makedirs(stock_raw_data_dir, exist_ok=True)

    # 1. è·å–æœ€è¿‘åŠå¹´çš„è‚¡ä»·å†å²
    hist_data = stock_yf.history(period="6mo") # MODIFIED: Changed from 1y to 6mo
    if hist_data.empty:
        logging.warning(f"æœªèƒ½è·å– {name}({code}) çš„è‚¡ä»·å†å²æ•°æ®ã€‚")
        return None # å¦‚æœæ²¡æœ‰è‚¡ä»·æ•°æ®ï¼Œåˆ™è·³è¿‡æ­¤è‚¡ç¥¨
    
    # MODIFIED: æŒ‰æ—¶é—´é™åºæ’åº (æœ€æ–°æ—¥æœŸåœ¨å‰)
    hist_data.sort_index(ascending=False, inplace=True)
    
    # ä¿å­˜åŸå§‹è‚¡ä»·æ•°æ®åˆ°CSV
    hist_data.to_csv(os.path.join(stock_raw_data_dir, f"{code}_price_6mo.csv")) # MODIFIED: Filename updated
    
    # æ›¿æ¢NaNä¸ºNoneï¼Œå¹¶å°†Dateç´¢å¼•è½¬ä¸ºåˆ—ï¼Œä»¥ä¾¿JSONåºåˆ—åŒ–ç”¨äºAIåˆ†æ
    hist_data.index = hist_data.index.strftime('%Y-%m-%d')
    hist_data = hist_data.where(pd.notnull(hist_data), None)
    stock_data_package["price_data"] = hist_data.reset_index().to_dict('records')

    # 2. è·å–è´¢åŠ¡æŠ¥è¡¨ (æœ€è¿‘å››å¹´)
    try:
        # è·å–å¹´åº¦æ•°æ®
        income_stmt = stock_yf.income_stmt.iloc[:, :4]
        balance_sheet = stock_yf.balance_sheet.iloc[:, :4]
        cash_flow = stock_yf.cashflow.iloc[:, :4]

        # ä¿å­˜åŸå§‹è´¢åŠ¡æ•°æ®åˆ°CSV
        income_stmt.to_csv(os.path.join(stock_raw_data_dir, f"{code}_income_4y.csv"))
        balance_sheet.to_csv(os.path.join(stock_raw_data_dir, f"{code}_balance_4y.csv"))
        cash_flow.to_csv(os.path.join(stock_raw_data_dir, f"{code}_cashflow_4y.csv"))

        # æ¸…ç†å¹¶æ ¼å¼åŒ–æ•°æ®ä»¥ç”¨äºAIåˆ†æ
        def format_financial_statement(df):
            df.columns = df.columns.strftime('%Y-%m-%d')
            transposed_df = df.transpose()
            transposed_df = transposed_df.where(pd.notnull(transposed_df), None)
            return transposed_df.reset_index().to_dict('records')

        stock_data_package["income_statement"] = format_financial_statement(income_stmt)
        stock_data_package["balance_sheet"] = format_financial_statement(balance_sheet)
        stock_data_package["cash_flow"] = format_financial_statement(cash_flow)
        
        logging.info(f"å·²ä¸ºè‚¡ç¥¨ {code} ä¿å­˜åŸå§‹æ•°æ®äº '{stock_raw_data_dir}'")

    except Exception as e:
        logging.warning(f"è·å– {name}({code}) çš„è´¢åŠ¡æ•°æ®æ—¶å‡ºé”™ (å¯èƒ½æ˜¯æ•°æ®ä¸å®Œæ•´): {e}ã€‚è´¢åŠ¡æ•°æ®å°†ä¸ºç©ºã€‚")
        stock_data_package["income_statement"] = []
        stock_data_package["balance_sheet"] = []
        stock_data_package["cash_flow"] = []

    return stock_data_package

# --- AI åˆ†æä¸ç»“æœä¿å­˜æ¨¡å— ---
@retry(retries=5, delay=10, backoff=2)
def analyze_stocks_in_batch(all_stock_data):
    """
    ä½¿ç”¨ Gemini AI æ¨¡å‹æ‰¹é‡åˆ†æè‚¡ç¥¨ã€‚
    ä¸€æ¬¡æ€§å‘é€æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼Œå¹¶æœŸæœ›è·å¾—æ‰¹é‡å“åº”ã€‚
    """
    if not AI_ANALYSIS_ENABLED:
        logging.warning("AI_ANALYSIS_ENABLED ä¸º Falseï¼Œè·³è¿‡ AI åˆ†æã€‚")
        return {}

    logging.info(f"æ­£åœ¨ä½¿ç”¨ Gemini AI æ‰¹é‡åˆ†æ {len(all_stock_data)} æ”¯è‚¡ç¥¨...")

    prompt_header = """
# è§’è‰²
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œã€ä¸€ä¸ä¸è‹Ÿçš„Aè‚¡è‚¡ç¥¨åˆ†æå¸ˆï¼Œæ“…é•¿é€šè¿‡è§£è¯»è‚¡ä»·èµ°åŠ¿å’Œè´¢åŠ¡æŠ¥è¡¨æ¥è¯†åˆ«é•¿æœŸä»·å€¼å’Œæ½œåœ¨é£é™©ã€‚

# ä»»åŠ¡
æ ¹æ®ä¸‹é¢æä¾›çš„ä¸€ç»„è‚¡ç¥¨åˆ—è¡¨åŠå…¶ä»Yahoo Financeè·å–çš„åŸå§‹æ•°æ®ï¼ˆè¿‘åŠå¹´è‚¡ä»·å†å²å’Œè¿‘å‡ å¹´å¹´åº¦è´¢åŠ¡æŠ¥è¡¨ï¼‰ï¼Œä½ å¿…é¡» **æ— ä¸€ä¾‹å¤–åœ°** å¯¹åˆ—è¡¨ä¸­çš„ **æ¯ä¸€æ”¯** è‚¡ç¥¨è¿›è¡Œç»¼åˆåˆ†æã€‚ç„¶åï¼Œæ ¹æ®ä»¥ä¸‹æ ¸å¿ƒæ ‡å‡†ï¼Œåˆ¤æ–­æ˜¯å¦åº”è¯¥å°†å…¶ **æ’é™¤** åœ¨ä¸€ä¸ªè§‚å¯Ÿåˆ—è¡¨ä¸­ï¼š

1.  **è¿‘æœŸæ˜æ˜¾ä¸‹è·Œèµ°åŠ¿**: è‚¡ç¥¨ä»·æ ¼åœ¨è¿‘æœŸï¼ˆä¾‹å¦‚æœ€è¿‘2ä¸ªæœˆï¼‰è¡¨ç°å‡ºæ¸…æ™°ã€æŒç»­çš„ä¸‹è·Œè¶‹åŠ¿ï¼Œæ²¡æœ‰ä¼ç¨³è¿¹è±¡ã€‚
2.  **æ¶¨å¹…å·¨å¤§ï¼Œç‚’ä½œæ¥è¿‘æ³¡æ²«**: è‚¡ç¥¨ä»·æ ¼åœ¨çŸ­æœŸå†…ï¼ˆä¾‹å¦‚è¿‡å»åŠå¹´ï¼‰å·²ç»ç»å†äº†éå¸¸å·¨å¤§çš„æ¶¨å¹…ï¼Œä¼°å€¼å¯èƒ½è¿‡é«˜ï¼Œå­˜åœ¨æ³¡æ²«é£é™©ã€‚
3.  **è´¢åŠ¡æœ‰ä¸¥é‡é—®é¢˜**: è‚¡ç¥¨å­˜åœ¨æ˜æ˜¾çš„è´¢åŠ¡é£é™©ï¼Œä¾‹å¦‚è¿ç»­äºæŸã€ç»è¥æ€§ç°é‡‘æµæŒç»­ä¸ºè´Ÿã€è´Ÿå€ºç‡è¿‡é«˜ä¸”æŒç»­æ¶åŒ–ç­‰ã€‚

# ç‰¹æ®Šæƒ…å†µå¤„ç†
- **æ•°æ®ä¸å®Œæ•´**: å¦‚æœæŸæ”¯è‚¡ç¥¨çš„å…³é”®è´¢åŠ¡æ•°æ®ï¼ˆå¦‚åˆ©æ¶¦è¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰ä¸¥é‡ç¼ºå¤±ï¼Œ**ä¸è¦å°†å…¶æ’é™¤**ã€‚åœ¨åˆ†æä¸­æ˜ç¡®æŒ‡å‡ºæ•°æ®ä¸å®Œæ•´ï¼Œå¹¶å»ºè®®ç”¨æˆ·è‡ªè¡Œæ ¸å®ã€‚
"""

    prompt_data_section = f"""
# å¾…åˆ†ææ•°æ®
è¿™æ˜¯å¾…åˆ†æçš„è‚¡ç¥¨åˆ—è¡¨åŠå…¶æ•°æ®ï¼š
```json
{json.dumps(all_stock_data, ensure_ascii=False, indent=2, default=str)}
```
"""
    
    prompt_footer = """
# åˆ†æä¸è¾“å‡ºè¦æ±‚
1.  **ä¸¥æ ¼éµå®ˆ**: ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ’é™¤æ ‡å‡†å’Œç‰¹æ®Šæƒ…å†µå¤„ç†è§„åˆ™ï¼Œå¯¹è¾“å…¥æ•°æ®ä¸­çš„ **æ¯ä¸€æ”¯è‚¡ç¥¨** è¿›è¡Œåˆ†æå¹¶å½¢æˆä¸€ä¸ªJSONå¯¹è±¡ã€‚
2.  **å®Œæ•´æ€§ä¿è¯**: è¿”å›çš„JSONæ•°ç»„ **å¿…é¡»** åŒ…å«ä¸è¾“å…¥æ•°æ®ä¸­ç›¸åŒæ•°é‡çš„å¯¹è±¡ã€‚**ç»å¯¹ä¸è¦é—æ¼ä»»ä½•ä¸€æ”¯è‚¡ç¥¨**ã€‚
3.  **å¼ºåˆ¶æ ¼å¼**: æ•°ç»„ä¸­æ¯ä¸ªå¯¹è±¡çš„ç»“æ„ **å¿…é¡»** å¦‚ä¸‹æ‰€ç¤ºã€‚`code` å­—æ®µè‡³å…³é‡è¦ã€‚
```json
{
  "code": "åŸå§‹è‚¡ç¥¨ä»£ç , ä¾‹å¦‚ '600519'",
  "should_exclude": boolean,
  "reason": "ä»…åœ¨ should_exclude ä¸º true æ—¶å¡«å†™æ­¤å­—æ®µï¼Œä»'è¿‘æœŸæ˜æ˜¾ä¸‹è·Œèµ°åŠ¿'ã€'æ¶¨å¹…å·¨å¤§æ¥è¿‘æ³¡æ²«'ã€'è´¢åŠ¡æœ‰ä¸¥é‡é—®é¢˜'ä¸­é€‰æ‹©ä¸€ä¸ªã€‚å¦‚æœshould_excludeä¸ºfalseï¼Œæ­¤å­—æ®µåº”ä¸ºç©ºå­—ç¬¦ä¸²æˆ–nullã€‚",
  "analysis": "æä¾›ä¸€å¥è¯çš„ç®€æ˜æ‰¼è¦çš„åˆ†æï¼Œè§£é‡Šä½ åšå‡ºè¯¥åˆ¤æ–­çš„æ ¸å¿ƒä¾æ®ã€‚å¯¹äºæ•°æ®ä¸å®Œæ•´çš„è‚¡ç¥¨ï¼Œshould_excludeåº”ä¸ºfalseï¼Œå¹¶åœ¨æ­¤å¤„è¯´æ˜â€˜æ•°æ®ä¸å®Œæ•´ï¼Œå»ºè®®ç”¨æˆ·è‡ªè¡Œæ ¸å®ç›¸å…³è´¢åŠ¡æŠ¥è¡¨ã€‚â€™"
}
```
4.  **çº¯å‡€è¾“å‡º**: ç¡®ä¿æœ€ç»ˆè¾“å‡ºæ˜¯ä¸€ä¸ªæ ¼å¼è‰¯å¥½çš„ã€å®Œæ•´çš„JSONæ•°ç»„ï¼Œå‰åä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡æœ¬æˆ–Markdownæ ‡è®°ã€‚
"""

    full_prompt = prompt_header + prompt_data_section + prompt_footer

    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        logging.info("æ­£åœ¨å‘ Gemini API å‘é€è¯·æ±‚ (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")
        start_time = time.time()
        response = model.generate_content(full_prompt)
        elapsed_time = time.time() - start_time
        logging.info(f"åœ¨ {elapsed_time:.2f} ç§’å†…æ”¶åˆ° Gemini API çš„å“åº”")
        
        # å¢åŠ æ—¥å¿—ä»¥è¿›è¡Œè°ƒè¯•
        logging.info(f"æ”¶åˆ°æ¥è‡ªAIçš„åŸå§‹å“åº”æ–‡æœ¬: {response.text[:1000]}...")

        # æ¸…ç†å¹¶è§£æJSONå“åº”
        response_text = response.text.strip()
        # æ›´ç¨³å¥åœ°ç§»é™¤ä»£ç å—æ ‡è®°
        match = re.search(r'```(json)?\n(.*)\n```', response_text, re.DOTALL)
        if match:
            response_text = match.group(2).strip()
        
        results_list = json.loads(response_text)
        
        if not isinstance(results_list, list):
            logging.error(f"å“åº”æ ¼å¼æ— æ•ˆ: æœŸæœ›æ˜¯åˆ—è¡¨ï¼Œä½†å¾—åˆ° {type(results_list)}")
            return {}
            
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºä»¥è‚¡ç¥¨ä»£ç ä¸ºé”®çš„å­—å…¸ï¼Œä¾¿äºæŸ¥æ‰¾
        results_map = {str(result.get("code")): result for result in results_list if result.get("code")}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è‚¡ç¥¨è¢«é—æ¼
        if len(results_map) < len(all_stock_data):
            logging.warning(f"AIå“åº”ä¸­é—æ¼äº† {len(all_stock_data) - len(results_map)} æ”¯è‚¡ç¥¨çš„åˆ†æç»“æœã€‚")

        logging.info(f"æ‰¹é‡åˆ†æå®Œæˆã€‚æ”¶åˆ° {len(results_map)} æ”¯è‚¡ç¥¨çš„åˆ†æç»“æœã€‚")
        return results_map
        
    except json.JSONDecodeError as e:
        logging.error(f"è§£æJSONå“åº”å¤±è´¥: {e}")
        logging.error(f"å¤±è´¥çš„å“åº”æ–‡æœ¬ (å‰500å­—ç¬¦): {response.text[:500]}...")
        return {}
    except Exception as e:
        logging.error(f"æ‰¹é‡AIåˆ†ææœŸé—´å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return {}

def save_analysis_results(all_stock_data):
    """å°†æœ€ç»ˆçš„åˆ†æç»“æœä¿å­˜ä¸ºJSONå’ŒMarkdownæ–‡ä»¶ã€‚"""
    logging.info("æ­£åœ¨ä¿å­˜æ‰€æœ‰åˆ†æç»“æœ...")
    current_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    report_data = [{"code": s["code"], "name": s["name"], "analysis_result": s.get("analysis_result", {})} for s in all_stock_data]
    
    # ä¿å­˜ä¸ºJSON
    json_path = os.path.join(ANALYSIS_RESULT_DIR, f"stock_analysis_{current_time}.json")
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜ä¸ºMarkdownæŠ¥å‘Š
    md_path = os.path.join(ANALYSIS_RESULT_DIR, f"stock_analysis_{current_time}.md")
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(f"# è‚¡ç¥¨ç­›é€‰åˆ†ææŠ¥å‘Š (AI-Powered)\n\n**åˆ†ææ—¶é—´:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        included = [s for s in report_data if not s.get('analysis_result', {}).get('should_exclude')]
        excluded = [s for s in report_data if s.get('analysis_result', {}).get('should_exclude')]
        
        f.write(f"## ç­›é€‰æ‘˜è¦\n\n- **æ€»åˆ†æè‚¡ç¥¨æ•°:** {len(report_data)}\n- **å»ºè®®ä¿ç•™:** {len(included)}\n- **å»ºè®®æ’é™¤:** {len(excluded)}\n\n")
        
        f.write("## å»ºè®®ä¿ç•™çš„è‚¡ç¥¨\n\n")
        if included:
            f.write("| è‚¡ç¥¨ä»£ç  | å…¬å¸åç§° | AIåˆ†ææ‘˜è¦ |\n|:---:|:---:|:---|\n")
            for stock in included:
                analysis_text = stock['analysis_result'].get('analysis', 'N/A')
                # å¦‚æœåŒ…å«å»ºè®®æ ¸å®çš„æ–‡æœ¬ï¼Œåˆ™åŠ ç²—ä»¥çªå‡ºæ˜¾ç¤º
                if "å»ºè®®ç”¨æˆ·è‡ªè¡Œæ ¸å®" in analysis_text:
                    analysis_text = f"**{analysis_text}**"
                f.write(f"| {stock['code']} | {stock['name']} | {analysis_text} |\n")
        else:
            f.write("æ— ã€‚\n\n")
        
        f.write("\n## å»ºè®®æ’é™¤çš„è‚¡ç¥¨\n\n")
        if excluded:
            f.write("| è‚¡ç¥¨ä»£ç  | å…¬å¸åç§° | æ’é™¤åŸå›  | AIåˆ†ææ‘˜è¦ |\n|:---:|:---:|:---:|:---|\n")
            for stock in excluded:
                f.write(f"| {stock['code']} | {stock['name']} | **{stock['analysis_result'].get('reason', 'N/A')}** | {stock['analysis_result'].get('analysis', 'N/A')} |\n")
        else:
            f.write("æ— ã€‚\n\n")
    
    logging.info(f"åˆ†æç»“æœå·²ä¿å­˜è‡³ {json_path} å’Œ {md_path}")
    return md_path

# --- ä¸»å‡½æ•° ---
def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºç¼–æ’æ•´ä¸ªåˆ†æå·¥ä½œæµã€‚"""
    logging.info("===== å¼€å§‹è‚¡ç¥¨ç­›é€‰å·¥ä½œæµ (Yahoo Finance + AIæ‰¹é‡åˆ†ææ¨¡å¼) =====")
    
    if not AI_ANALYSIS_ENABLED:
        logging.error("Gemini AI æœªå¯ç”¨æˆ–é…ç½®å¤±è´¥ï¼Œæ— æ³•æ‰§è¡Œåˆ†æã€‚ç¨‹åºé€€å‡ºã€‚")
        return

    # 1. è·å–æœ€æ–°æŠ¥å‘Šå¹¶æå–è‚¡ç¥¨åˆ—è¡¨
    report_path = get_latest_report()
    if not report_path:
        logging.error("æœªæ‰¾åˆ°å¯ç”¨çš„æ¯æ—¥æŠ¥å‘Šï¼Œç¨‹åºé€€å‡ºã€‚")
        return
    
    stocks_to_analyze = extract_stock_recommendations(report_path)
    if not stocks_to_analyze:
        logging.error("æ— æ³•ä»æŠ¥å‘Šä¸­æå–è‚¡ç¥¨åˆ—è¡¨ï¼Œç¨‹åºé€€å‡ºã€‚")
        return
    
    # --- æ­¥éª¤ 1: ä»Yahoo Financeè·å–æ•°æ® ---
    logging.info("\n--- æ­¥éª¤ 1: ä» Yahoo Finance è·å–æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ® ---")
    all_stock_data = []
    
    for stock in tqdm(stocks_to_analyze, desc="è·å–å¹¶ä¿å­˜é›…è™è´¢ç»æ•°æ®"):
        stock_data_package = fetch_stock_data_from_yahoo(stock)
        if stock_data_package:
            all_stock_data.append(stock_data_package)
        else:
            logging.warning(f"æ— æ³•è·å–è‚¡ç¥¨ {stock['code']} çš„æ•°æ®ï¼Œå°†åœ¨åˆ†æä¸­è·³è¿‡ã€‚")

    if not all_stock_data:
        logging.error("æœªèƒ½æˆåŠŸè·å–ä»»ä½•è‚¡ç¥¨çš„æ•°æ®ï¼Œç¨‹åºé€€å‡ºã€‚")
        return

    logging.info(f"æˆåŠŸè·å–äº† {len(all_stock_data)} / {len(stocks_to_analyze)} æ”¯è‚¡ç¥¨çš„æ•°æ®ã€‚")
    
    # --- æ­¥éª¤ 2: AI æ‰¹é‡åˆ†æ ---
    logging.info("\n--- æ­¥éª¤ 2: å¼€å§‹ AI æ‰¹é‡åˆ†æ ---")
    
    analysis_results_map = analyze_stocks_in_batch(all_stock_data)
    
    # ä¸ºæœªæ”¶åˆ°åˆ†æç»“æœçš„è‚¡ç¥¨è®¾ç½®é»˜è®¤é”™è¯¯ä¿¡æ¯
    error_result = {"should_exclude": True, "reason": "åˆ†æå¤±è´¥", "analysis": "æœªèƒ½ä»AIè·å–å¯¹æ­¤è‚¡ç¥¨çš„æœ‰æ•ˆåˆ†æã€‚æ£€æŸ¥æ—¥å¿—ä¸­AIçš„åŸå§‹å“åº”ã€‚"}
    
    # å°†åˆ†æç»“æœæ˜ å°„å›åŸå§‹æ•°æ®åˆ—è¡¨
    for stock_data in all_stock_data:
        stock_code = stock_data['code']
        stock_data['analysis_result'] = analysis_results_map.get(stock_code, error_result)

    logging.info("å·²æˆåŠŸæ˜ å°„æ‰€æœ‰AIåˆ†æç»“æœã€‚")
    
    # --- æ­¥éª¤ 3: ä¿å­˜æœ€ç»ˆæŠ¥å‘Š ---
    logging.info("\n--- æ­¥éª¤ 3: ä¿å­˜æœ€ç»ˆåˆ†ææŠ¥å‘Š ---")
    final_report_path = save_analysis_results(all_stock_data)
    
    logging.info("===== è‚¡ç¥¨ç­›é€‰å·¥ä½œæµæˆåŠŸå®Œæˆ =====")
    if final_report_path:
        # åœ¨æ§åˆ¶å°æ¸…æ™°åœ°æ‰“å°å‡ºMDæ–‡ä»¶å
        print("\n" + "="*60)
        print("ğŸ‰ åˆ†ææŠ¥å‘Šå·²æˆåŠŸç”Ÿæˆï¼")
        print(f"   Markdown æ–‡ä»¶å: {os.path.basename(final_report_path)}")
        print(f"   å®Œæ•´è·¯å¾„: {final_report_path}")
        print("="*60)

if __name__ == "__main__":
    main()
